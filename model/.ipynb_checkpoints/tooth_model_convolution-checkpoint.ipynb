{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "json_dir = '/root/notebooks/0858611-2/tooth_xray/model/700_700/mapping.json'\n",
    "with open(json_dir) as json_file:\n",
    "    json_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level(mean):\n",
    "    if mean>=0 and mean<=2:\n",
    "        return 'normal'\n",
    "    elif mean>=3 and mean<=4:\n",
    "        return 'medium'\n",
    "    elif mean>4:\n",
    "        return 'serious'\n",
    "    else:\n",
    "        return 'over_range'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/Images_padding/037621 062310 x_12_.png None\n",
      "Dataset/Images_padding/037621 062310 x_13_.png None\n",
      "Dataset/Images_padding/037621 062310 x_26_.png None\n",
      "Dataset/Images_padding/037621 062310 x_25_.png None\n",
      "Dataset/Images_padding/039462 100517 x_14_.png None\n",
      "Dataset/Images_padding/039462 100517 x_22_.png None\n",
      "Dataset/Images_padding/039462 100517 x_21_.png None\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "import pandas as pd\n",
    "img_path = []\n",
    "img_cal = []\n",
    "img_cal_mean = []\n",
    "img_cal_level = []\n",
    "\n",
    "for key in json_data:\n",
    "    try:\n",
    "        new_path = key.replace(\"Dataset/Images\", \"/root/notebooks/0858611-2/tooth_xray/model/700_700/Images\")\n",
    "        max_cal = int(max(json_data[key]))\n",
    "        img_cal_level.append(get_level(max_cal))\n",
    "        img_cal_mean.append(str(max_cal))\n",
    "        img_path.append(new_path)\n",
    "        img_cal.append(json_data[key])\n",
    "    except:\n",
    "        print(key,json_data[key])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493\n",
      "1493\n",
      "1493\n",
      "1493\n",
      "802\n",
      "456\n",
      "223\n"
     ]
    }
   ],
   "source": [
    "print(len(img_path))\n",
    "print(len(img_cal))\n",
    "print(len(img_cal_mean))\n",
    "print(len(img_cal_level))\n",
    "print(img_cal_level.count('normal'))\n",
    "print(img_cal_level.count('medium'))\n",
    "print(img_cal_level.count('serious'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path img_cal img_cal_mean  \\\n",
      "0  /root/notebooks/0858611-2/tooth_xray/model/700...  [5, 3]            5   \n",
      "1  /root/notebooks/0858611-2/tooth_xray/model/700...  [3, 4]            4   \n",
      "2  /root/notebooks/0858611-2/tooth_xray/model/700...  [7, 9]            9   \n",
      "3  /root/notebooks/0858611-2/tooth_xray/model/700...  [4, 5]            5   \n",
      "4  /root/notebooks/0858611-2/tooth_xray/model/700...  [4, 3]            4   \n",
      "\n",
      "  img_cal_level  \n",
      "0       serious  \n",
      "1        medium  \n",
      "2       serious  \n",
      "3       serious  \n",
      "4        medium  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dict = {\"image_path\": img_path,  \n",
    "        \"img_cal\": img_cal,\n",
    "        \"img_cal_mean\":img_cal_mean,\n",
    "        \"img_cal_level\":img_cal_level\n",
    "       }\n",
    "\n",
    "tooth_dataframe = pd.DataFrame(dict)\n",
    "print(tooth_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tooth_dataframe = tooth_dataframe[tooth_dataframe.img_cal_level != 'over_range']\n",
    "\n",
    "normal_dataframe = tooth_dataframe[tooth_dataframe.img_cal_level == 'normal']\n",
    "medium_dataframe = tooth_dataframe[tooth_dataframe.img_cal_level == 'medium']\n",
    "serious_dataframe = tooth_dataframe[tooth_dataframe.img_cal_level == 'serious']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1481, 256, 256, 1)\n",
      "(1481,)\n"
     ]
    }
   ],
   "source": [
    "#img to array and resize \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "imgsize = (256,256)\n",
    "\n",
    "def imgpath_list_to_array_list(imgpath_list,imgsize=(256,256)):\n",
    "    array_list = []\n",
    "    for img_path in imgpath_list:\n",
    "        img = cv2.imread(img_path,0)\n",
    "        img = cv2.resize(img,imgsize)\n",
    "        #img = img[:,:,0]\n",
    "        #img = (img-127.5)/127.5\n",
    "        array_list.append(img.reshape(256,256,1))\n",
    "    return np.array(array_list)\n",
    "\n",
    "def label_list_to_num(train_label):\n",
    "    label_array = []\n",
    "    for symptom in train_label:\n",
    "        if symptom == 'normal':\n",
    "            label_array.append(0)\n",
    "        if symptom == 'medium':\n",
    "            label_array.append(1)\n",
    "        if symptom == 'serious':\n",
    "            label_array.append(2)\n",
    "    return np.array(label_array)\n",
    "\n",
    "train_data_array = imgpath_list_to_array_list(tooth_dataframe.image_path)\n",
    "train_label_array = label_list_to_num(tooth_dataframe.img_cal_level)\n",
    "\n",
    "normal_data_array = imgpath_list_to_array_list(normal_dataframe.image_path)\n",
    "normal_label_array = label_list_to_num(normal_dataframe.img_cal_level)\n",
    "medium_data_array = imgpath_list_to_array_list(medium_dataframe.image_path)\n",
    "medium_label_array= label_list_to_num(medium_dataframe.img_cal_level)\n",
    "serious_data_array = imgpath_list_to_array_list(serious_dataframe.image_path)\n",
    "serious_label_array = label_list_to_num(serious_dataframe.img_cal_level)\n",
    "\n",
    "\n",
    "print(train_data_array.shape)\n",
    "print(train_label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input,Dropout\n",
    "\n",
    "\n",
    "def my_convolution_model(input_shape, classes):\n",
    "    inputs=Input(input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(classes)(x)\n",
    "    model = Model(inputs, x)\n",
    "    model.compile(optimizer='adam',\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "          metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape= (256,256,1)\n",
    "classes    = 3\n",
    "batch_size = 256\n",
    "epochs     = 1\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "with mirrored_strategy.scope():\n",
    "    model_convolution = my_convolution_model(input_shape, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 254, 254, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              102762496 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 104,232,451\n",
      "Trainable params: 104,232,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_convolution.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 281 samples\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "1200/1200 [==============================] - 5s 4ms/sample - loss: 34.7071 - accuracy: 0.4183 - val_loss: 1.2918 - val_accuracy: 0.1993\n"
     ]
    }
   ],
   "source": [
    "history = model_convolution.fit(train_data_array[:1200], train_label_array[:1200], epochs=epochs, \n",
    "                     validation_data=(train_data_array[1200:], train_label_array[1200:]),shuffle=True,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpredict = my_convolution_model(input_shape, classes)\n",
    "\n",
    "weights = model_convolution.get_weights()\n",
    "modelpredict.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/1 - 1s - loss: 1.2882 - accuracy: 0.1993\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model_convolution.evaluate(train_data_array[1200:],  train_label_array[1200:], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/1 - 0s - loss: 1.2882 - accuracy: 0.1993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2918092500272595, 0.19928825]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_convolution.evaluate(train_data_array[1200:],  train_label_array[1200:], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "following is recall rate\n",
      "\n",
      "# Evaluate on normal_data\n",
      "802/1 - 2s - loss: 1.5597 - accuracy: 0.0000e+00\n",
      "\n",
      "# Evaluate on medium_data\n",
      "456/1 - 1s - loss: 0.7891 - accuracy: 1.0000\n",
      "\n",
      "# Evaluate on serious_data\n",
      "223/1 - 1s - loss: 1.1030 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1008103161114748, 0.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('following is recall rate')\n",
    "print('\\n# Evaluate on normal_data')\n",
    "model_convolution.evaluate(normal_data_array,normal_label_array, verbose=2)\n",
    "\n",
    "print('\\n# Evaluate on medium_data')\n",
    "model_convolution.evaluate(medium_data_array,medium_label_array, verbose=2)\n",
    "\n",
    "print('\\n# Evaluate on serious_data')\n",
    "model_convolution.evaluate(serious_data_array,serious_label_array, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def recall_accuracy_rate(test_data_array,test_label_array,model):\n",
    "    model_predict =[]\n",
    "    for img in test_data_array:\n",
    "        reshape = img.reshape(1,256,256,1)\n",
    "        image = tf.cast(reshape, tf.float32)\n",
    "        model_predict.append(np.argmax(model.predict(image)))\n",
    "        \n",
    "    matrix = confusion_matrix(test_label_array, model_predict)\n",
    "    matrix_split = np.split(matrix,3,axis=1)\n",
    "    print('column:* is prediction result')\n",
    "    print('row*: is real class')\n",
    "    dict = {#\"\": img_path,\n",
    "            \"class:0\":matrix_split[0].reshape(3),\n",
    "            \"class:1\":matrix_split[1].reshape(3),\n",
    "            \"class:2\":matrix_split[2].reshape(3)\n",
    "           }\n",
    "    \n",
    "    predict_table = pd.DataFrame(dict)\n",
    "    return predict_table,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column:* is prediction result\n",
      "row*: is real class\n",
      "The class:0 precision is nan% in 0 prediction and recall is 0.0000% in 182 sample\n",
      "\n",
      "The class:1 precision is 19.9288% in 281 prediction and recall is 100.0000% in 56 sample\n",
      "\n",
      "The class:2 precision is nan% in 0 prediction and recall is 0.0000% in 43 sample\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "predict_table,matrix = recall_accuracy_rate(train_data_array[1200:],train_label_array[1200:],modelpredict)\n",
    "for i in range(len(predict_table.columns)):\n",
    "    p = precision(i,matrix)\n",
    "    r = recall(i,matrix) \n",
    "    print('The {} precision is {:.4f}% in {} prediction and recall is {:.4f}% in {} sample'\n",
    "          .format(predict_table.columns[i],p*100,matrix[:,i].sum(),r*100,matrix[i, :].sum()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class:0</th>\n",
       "      <th>class:1</th>\n",
       "      <th>class:2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class:0  class:1  class:2\n",
       "0        0      182        0\n",
       "1        0       56        0\n",
       "2        0       43        0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL, os\n",
    "from PIL import Image\n",
    "import random \n",
    "import csv\n",
    "\n",
    "img_path_rotate = img_path[:5] \n",
    "# It is your img_path list  \n",
    "\n",
    "image_label_array = train_label_array[:5] \n",
    "# It is label of above img_path\n",
    "\n",
    "nums = 5\n",
    "# It should small than imgs*degree range  \n",
    "# ex:get 3 img and degree_range is [-5,5] ,should small than 3*(5-(-5)) = 30 \n",
    "\n",
    "save_rotate_img_dir = '/root/notebooks/0858611-2/tooth_xray/model/700_700/image_generate_all_rotate'\n",
    "#save_img_path\n",
    "save_csv_path = '/root/notebooks/0858611-2/tooth_xray/model/700_700/image_generate_all_rotate/label.csv'\n",
    "#save_csv_path it contain rotate_img_path & label\n",
    "ratate_range = [-10,10] \n",
    "# means -10 drgree to 10 degree\n",
    "\n",
    "def rotate_save_img(origin_img,label,save_dir,save_csv_path,degree,count):\n",
    "    img = Image.open(origin_img)\n",
    "    result_name = origin_img.split('/')[-1][:-4]\n",
    "    rotate_image_name = save_dir+'/'+result_name+'_'+'rotate'+'_'+str(degree)+ '.png'\n",
    "    if os.path.exists(rotate_image_name) == True:\n",
    "        return count\n",
    "    else:\n",
    "        img.rotate(degree).save(rotate_image_name)\n",
    "        with open(save_csv_path, 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([rotate_image_name,label])\n",
    "        count += 1\n",
    "        return count\n",
    "\n",
    "def create_ratate_images(image_path_list,image_label_array,nums,save_dir,save_csv_path,ratate_range=[0,1]):\n",
    "    if len(image_path_list)*(ratate_range[1]-ratate_range[0]) < nums:\n",
    "        print('You have too few image with all rotate degree')\n",
    "        return\n",
    "    ratate_img_path_list = []\n",
    "    rotate_image_label_array =[]\n",
    "    count = 0\n",
    "    while count < nums:\n",
    "        for origin_img,label in zip(image_path_list,image_label_array):\n",
    "            if count < nums:\n",
    "                degree = random.randrange(ratate_range[0],ratate_range[1])\n",
    "                count = rotate_save_img(origin_img,label,save_dir,save_csv_path,degree,count)\n",
    "            else:\n",
    "                return ratate_img_path_list,rotate_image_label_array\n",
    "    return ratate_img_path_list,rotate_image_label_array\n",
    "\n",
    "if os.path.exists(save_csv_path) == True:\n",
    "    print('csv is exist')\n",
    "else:\n",
    "    with open(save_csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Image_path','label'])\n",
    "        \n",
    "create_ratate_images(img_path_rotate,image_label_array,nums,save_rotate_img_dir,save_csv_path,[-10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
