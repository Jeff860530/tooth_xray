{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Image_path  label\n",
      "0  /root/notebooks/0858611-2/tooth_xray/model/700...      2\n",
      "1  /root/notebooks/0858611-2/tooth_xray/model/700...      1\n",
      "2  /root/notebooks/0858611-2/tooth_xray/model/700...      2\n",
      "3  /root/notebooks/0858611-2/tooth_xray/model/700...      2\n",
      "4  /root/notebooks/0858611-2/tooth_xray/model/700...      1\n"
     ]
    }
   ],
   "source": [
    "#prepare training data\n",
    "import pandas as pd\n",
    "train_csv_path = '/root/notebooks/0858611-2/tooth_xray/model/700_700/image_generate_all_rotate/train_label.csv'\n",
    "train_tooth_dataframe = pd.read_csv (train_csv_path)\n",
    "#tooth_dataframe = tooth_dataframe.sort_values(by=['Image_path'][-35:])\n",
    "print (train_tooth_dataframe.head())\n",
    "\n",
    "train_img_path_list = train_tooth_dataframe.Image_path\n",
    "train_img_label_list = train_tooth_dataframe.label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Image_path  label\n",
      "0  /root/notebooks/0858611-2/tooth_xray/model/700...      0\n",
      "1  /root/notebooks/0858611-2/tooth_xray/model/700...      0\n",
      "2  /root/notebooks/0858611-2/tooth_xray/model/700...      2\n",
      "3  /root/notebooks/0858611-2/tooth_xray/model/700...      1\n",
      "4  /root/notebooks/0858611-2/tooth_xray/model/700...      2\n"
     ]
    }
   ],
   "source": [
    "#prepare test data\n",
    "import pandas as pd\n",
    "test_csv_path = '/root/notebooks/0858611-2/tooth_xray/model/700_700/image_generate_all_rotate/test_label.csv'\n",
    "test_tooth_dataframe = pd.read_csv (test_csv_path)\n",
    "#tooth_dataframe = tooth_dataframe.sort_values(by=['Image_path'][-35:])\n",
    "print (test_tooth_dataframe.head())\n",
    "test_img_path_list = test_tooth_dataframe.Image_path\n",
    "test_img_label_list = test_tooth_dataframe.label\n",
    "\n",
    "test_data_array = imgpath_list_to_array_list(test_tooth_dataframe.Image_path)\n",
    "test_label_array = np.array(test_tooth_dataframe.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12400\n",
      "8000\n",
      "3600\n"
     ]
    }
   ],
   "source": [
    "normal_dataframe = train_tooth_dataframe[train_tooth_dataframe.label == 0]\n",
    "medium_dataframe = train_tooth_dataframe[train_tooth_dataframe.label == 1]\n",
    "serious_dataframe = train_tooth_dataframe[train_tooth_dataframe.label == 2]\n",
    "print(len(normal_dataframe))\n",
    "print(len(medium_dataframe))\n",
    "print(len(serious_dataframe))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "normal_dataframe = shuffle(normal_dataframe)\n",
    "medium_dataframe = shuffle(medium_dataframe)\n",
    "serious_dataframe = shuffle(serious_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n"
     ]
    }
   ],
   "source": [
    "min_len = min(len(normal_dataframe),len(medium_dataframe),len(serious_dataframe))\n",
    "print(min_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800\n",
      "                                              Image_path  label\n",
      "3237   /root/notebooks/0858611-2/tooth_xray/model/700...      0\n",
      "749    /root/notebooks/0858611-2/tooth_xray/model/700...      0\n",
      "18459  /root/notebooks/0858611-2/tooth_xray/model/700...      0\n",
      "10069  /root/notebooks/0858611-2/tooth_xray/model/700...      2\n",
      "15896  /root/notebooks/0858611-2/tooth_xray/model/700...      2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_tooth_dataframe = pd.concat([normal_dataframe[:min_len],medium_dataframe[:min_len],serious_dataframe[:min_len]],axis=0)\n",
    "print(len(train_tooth_dataframe))\n",
    "train_tooth_dataframe = shuffle(train_tooth_dataframe)\n",
    "print(train_tooth_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img to array and resize \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "imgsize = (256,256)\n",
    "\n",
    "def imgpath_list_to_array_list(imgpath_list,imgsize=(256,256)):\n",
    "    array_list = []\n",
    "    for img_path in imgpath_list:\n",
    "        img = cv2.imread(img_path,0)\n",
    "        img = cv2.resize(img,imgsize)\n",
    "        #img = img[:,:,0]\n",
    "        #img = (img-127.5)/127.5\n",
    "        array_list.append(img.reshape(256,256,1))\n",
    "    return np.array(array_list)\n",
    "\n",
    "# def label_list_to_num(train_label):\n",
    "#     label_array = []\n",
    "#     for symptom in train_label:\n",
    "#         if symptom == 'normal':\n",
    "#             label_array.append(0)\n",
    "#         if symptom == 'medium':\n",
    "#             label_array.append(1)\n",
    "#         if symptom == 'serious':\n",
    "#             label_array.append(2)\n",
    "#     return np.array(label_array)\n",
    "\n",
    "train_data_array = imgpath_list_to_array_list(train_tooth_dataframe.Image_path)\n",
    "train_label_array = np.array(train_tooth_dataframe.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10800, 256, 256, 1)\n",
      "(10800,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_array.shape)\n",
    "print(train_label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input,Dropout\n",
    "\n",
    "\n",
    "def my_convolution_model(input_shape, classes):\n",
    "    inputs=Input(input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(classes)(x)\n",
    "    model = Model(inputs, x)\n",
    "    model.compile(optimizer='adam',\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "          metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape= (256,256,1)\n",
    "classes    = 3\n",
    "batch_size = 128\n",
    "epochs     = 30\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "with mirrored_strategy.scope():\n",
    "    model_convolution = my_convolution_model(input_shape, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 254, 254, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              102762496 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 104,232,451\n",
      "Trainable params: 104,232,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_convolution.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 10800 data, 9720 for training , 1080 for validation\n"
     ]
    }
   ],
   "source": [
    "data_to_train_rate = 0.9\n",
    "data_to_validation_rate = 0.1\n",
    "train_unms = int(len(train_label_array)*data_to_train_rate)\n",
    "print('Have {} data, {} for training , {} for validation'\n",
    "      .format(len(train_label_array),train_unms,len(train_label_array)-train_unms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9720 samples, validate on 1080 samples\n",
      "Epoch 1/30\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "9720/9720 [==============================] - 21s 2ms/sample - loss: 1.8932 - accuracy: 0.3958 - val_loss: 1.0404 - val_accuracy: 0.4843\n",
      "Epoch 2/30\n",
      "9720/9720 [==============================] - 8s 777us/sample - loss: 1.0049 - accuracy: 0.5002 - val_loss: 0.9640 - val_accuracy: 0.5241\n",
      "Epoch 3/30\n",
      "9720/9720 [==============================] - 8s 801us/sample - loss: 0.8843 - accuracy: 0.5891 - val_loss: 0.8248 - val_accuracy: 0.6315\n",
      "Epoch 4/30\n",
      "9720/9720 [==============================] - 8s 803us/sample - loss: 0.7185 - accuracy: 0.6792 - val_loss: 0.6461 - val_accuracy: 0.7130\n",
      "Epoch 5/30\n",
      "9720/9720 [==============================] - 8s 795us/sample - loss: 0.5272 - accuracy: 0.7766 - val_loss: 0.5557 - val_accuracy: 0.7722\n",
      "Epoch 6/30\n",
      "9720/9720 [==============================] - 8s 778us/sample - loss: 0.4040 - accuracy: 0.8372 - val_loss: 0.4438 - val_accuracy: 0.8259\n",
      "Epoch 7/30\n",
      "9720/9720 [==============================] - 8s 795us/sample - loss: 0.2800 - accuracy: 0.8895 - val_loss: 0.3136 - val_accuracy: 0.8704\n",
      "Epoch 8/30\n",
      "9720/9720 [==============================] - 8s 780us/sample - loss: 0.2124 - accuracy: 0.9225 - val_loss: 0.3166 - val_accuracy: 0.8880\n",
      "Epoch 9/30\n",
      "9720/9720 [==============================] - 8s 775us/sample - loss: 0.1745 - accuracy: 0.9404 - val_loss: 0.2888 - val_accuracy: 0.8981\n",
      "Epoch 10/30\n",
      "9720/9720 [==============================] - 7s 770us/sample - loss: 0.1359 - accuracy: 0.9565 - val_loss: 0.2457 - val_accuracy: 0.9204\n",
      "Epoch 11/30\n",
      "9720/9720 [==============================] - 7s 769us/sample - loss: 0.1121 - accuracy: 0.9629 - val_loss: 0.2375 - val_accuracy: 0.9139\n",
      "Epoch 12/30\n",
      "9720/9720 [==============================] - 8s 777us/sample - loss: 0.0927 - accuracy: 0.9709 - val_loss: 0.2391 - val_accuracy: 0.9185\n",
      "Epoch 13/30\n",
      "9720/9720 [==============================] - 8s 782us/sample - loss: 0.0727 - accuracy: 0.9759 - val_loss: 0.2911 - val_accuracy: 0.9278\n",
      "Epoch 14/30\n",
      "9720/9720 [==============================] - 7s 766us/sample - loss: 0.0564 - accuracy: 0.9823 - val_loss: 0.3299 - val_accuracy: 0.9111\n",
      "Epoch 15/30\n",
      "9720/9720 [==============================] - 7s 761us/sample - loss: 0.0624 - accuracy: 0.9793 - val_loss: 0.2923 - val_accuracy: 0.9352\n",
      "Epoch 16/30\n",
      "9720/9720 [==============================] - 7s 762us/sample - loss: 0.0474 - accuracy: 0.9866 - val_loss: 0.2400 - val_accuracy: 0.9250\n",
      "Epoch 17/30\n",
      "9720/9720 [==============================] - 8s 772us/sample - loss: 0.0533 - accuracy: 0.9846 - val_loss: 0.2286 - val_accuracy: 0.9315\n",
      "Epoch 18/30\n",
      "9720/9720 [==============================] - 8s 791us/sample - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.2812 - val_accuracy: 0.9306\n",
      "Epoch 19/30\n",
      "9720/9720 [==============================] - 7s 766us/sample - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.2510 - val_accuracy: 0.9426\n",
      "Epoch 20/30\n",
      "9720/9720 [==============================] - 7s 764us/sample - loss: 0.0362 - accuracy: 0.9897 - val_loss: 0.2658 - val_accuracy: 0.9407\n",
      "Epoch 21/30\n",
      "9720/9720 [==============================] - 8s 781us/sample - loss: 0.0377 - accuracy: 0.9900 - val_loss: 0.2160 - val_accuracy: 0.9389\n",
      "Epoch 22/30\n",
      "9720/9720 [==============================] - 8s 780us/sample - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.2326 - val_accuracy: 0.9444\n",
      "Epoch 23/30\n",
      "9720/9720 [==============================] - 7s 765us/sample - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.2541 - val_accuracy: 0.9500\n",
      "Epoch 24/30\n",
      "9720/9720 [==============================] - 7s 761us/sample - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.2420 - val_accuracy: 0.9546\n",
      "Epoch 25/30\n",
      "9720/9720 [==============================] - 8s 786us/sample - loss: 0.0376 - accuracy: 0.9894 - val_loss: 0.2280 - val_accuracy: 0.9426\n",
      "Epoch 26/30\n",
      "9720/9720 [==============================] - 8s 781us/sample - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.2180 - val_accuracy: 0.9417\n",
      "Epoch 27/30\n",
      "9720/9720 [==============================] - 7s 767us/sample - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.2758 - val_accuracy: 0.9398\n",
      "Epoch 28/30\n",
      "9720/9720 [==============================] - 8s 778us/sample - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.2339 - val_accuracy: 0.9500\n",
      "Epoch 29/30\n",
      "9720/9720 [==============================] - 8s 795us/sample - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.1855 - val_accuracy: 0.9546\n",
      "Epoch 30/30\n",
      "9720/9720 [==============================] - 7s 764us/sample - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.2007 - val_accuracy: 0.9593\n"
     ]
    }
   ],
   "source": [
    "history = model_convolution.fit(train_data_array[:train_unms], train_label_array[:train_unms], epochs=epochs, \n",
    "                     validation_data=(train_data_array[train_unms:], train_label_array[train_unms:]),shuffle=True,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /root/notebooks/0858611-2/tooth_xray/model/700_700/image_generate_all_rotate/model_weight/assets\n"
     ]
    }
   ],
   "source": [
    "modelpredict = my_convolution_model(input_shape, classes)\n",
    "\n",
    "weights = model_convolution.get_weights()\n",
    "modelpredict.set_weights(weights)\n",
    "modelpredict.save('/root/notebooks/0858611-2/tooth_xray/model/700_700/image_generate_all_rotate/model_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1 - 2s - loss: 0.1041 - accuracy: 0.9593\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model_convolution.evaluate(train_data_array[train_unms:],  train_label_array[train_unms:], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1 - 1s - loss: 0.1041 - accuracy: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20067767298400954, 0.9592593]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_convolution.evaluate(train_data_array[train_unms:],  train_label_array[train_unms:], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def recall_accuracy_rate(test_data_array,test_label_array,model):\n",
    "    model_predict =[]\n",
    "    for img in test_data_array:\n",
    "        reshape = img.reshape(1,256,256,1)\n",
    "        image = tf.cast(reshape, tf.float32)\n",
    "        model_predict.append(np.argmax(model.predict(image)))\n",
    "        \n",
    "    matrix = confusion_matrix(test_label_array, model_predict)\n",
    "    matrix_split = np.split(matrix,3,axis=1)\n",
    "    print('column:* is prediction result')\n",
    "    print('row*: is real class')\n",
    "    dict = {\n",
    "            \"class:0\":matrix_split[0].reshape(3),\n",
    "            \"class:1\":matrix_split[1].reshape(3),\n",
    "            \"class:2\":matrix_split[2].reshape(3)\n",
    "           }\n",
    "    \n",
    "    predict_table = pd.DataFrame(dict)\n",
    "    return predict_table,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(label, confusion_matrix):\n",
    "    col = confusion_matrix[:, label]\n",
    "    return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "def recall(label, confusion_matrix):\n",
    "    row = confusion_matrix[label, :]\n",
    "    return confusion_matrix[label, label] / row.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column:* is prediction result\n",
      "row*: is real class\n",
      "The class:0 precision is 66.9544% in 3244 prediction and recall is 59.6703% in 3640 sample\n",
      "\n",
      "The class:1 precision is 22.0930% in 1720 prediction and recall is 33.9286% in 1120 sample\n",
      "\n",
      "The class:2 precision is 26.8293% in 656 prediction and recall is 20.4651% in 860 sample\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing data\n",
    "predict_table1,matrix1 = recall_accuracy_rate(test_data_array,test_label_array,modelpredict)\n",
    "for i in range(len(predict_table1.columns)):\n",
    "    p = precision(i,matrix1)\n",
    "    r = recall(i,matrix1) \n",
    "    print('The {} precision is {:.4f}% in {} prediction and recall is {:.4f}% in {} sample'\n",
    "          .format(predict_table1.columns[i],p*100,matrix1[:,i].sum(),r*100,matrix1[i, :].sum()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class:0</th>\n",
       "      <th>class:1</th>\n",
       "      <th>class:2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2172</td>\n",
       "      <td>1056</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>672</td>\n",
       "      <td>380</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>284</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class:0  class:1  class:2\n",
       "0     2172     1056      412\n",
       "1      672      380       68\n",
       "2      400      284      176"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_table1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
