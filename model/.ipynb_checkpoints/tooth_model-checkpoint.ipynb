{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import os\n",
    "# import random\n",
    "\n",
    "# img_dir = '/root/notebooks/0858611-2/dental/model/tooth_data/'\n",
    "# img_file_list = [img for img in os.listdir(img_dir) ]\n",
    "# with open('/root/notebooks/0858611-2/dental/model/data.csv', 'w', newline='') as csvfile:\n",
    "\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     seqcal = ['1','2','3']\n",
    "#     seqsymptom = ['E','M','H']\n",
    "\n",
    "#     writer.writerow(['Image Index', 'CAL', 'symptom'])\n",
    "#     for index,img in enumerate(img_file_list[:-2]):\n",
    "#         cal = random.choice(seqcal)\n",
    "#         symptom = random.choice(seqsymptom)\n",
    "#         writer.writerow([img ,cal,symptom ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:2\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "data.csv\n",
      "max_img_hight: 645\n",
      "max_img_width: 522\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img_dir = '/root/notebooks/0858611-2/dental/model/tooth_data'\n",
    "img_file_list = [img for img in os.listdir(img_dir)]\n",
    "img_shape_list = []\n",
    "img_hight = []\n",
    "img_width = []\n",
    "\n",
    "for img_path in img_file_list:\n",
    "    try:\n",
    "        img = cv2.imread(img_dir+'/'+img_path)\n",
    "        #print(img.shape)\n",
    "        img_shape_list.append(img.shape)\n",
    "        img_hight.append(img.shape[0])\n",
    "        img_width.append(img.shape[1])\n",
    "    except:\n",
    "        print(img_path)\n",
    "print('max_img_hight:',max(img_hight))\n",
    "print('max_img_width:',max(img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sort_by_hight  = sorted(img_shape_list, key=lambda x: x[0])\n",
    "sort_by_width  = sorted(img_shape_list, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(334, 124, 3), (362, 171, 3), (481, 198, 3), (483, 208, 3), (492, 277, 3), (495, 247, 3), (502, 240, 3), (502, 174, 3), (519, 359, 3), (522, 313, 3), (523, 245, 3), (525, 371, 3), (525, 191, 3), (528, 441, 3), (529, 238, 3), (535, 419, 3), (542, 319, 3), (543, 274, 3), (553, 304, 3), (568, 397, 3), (570, 225, 3), (572, 256, 3), (574, 329, 3), (578, 485, 3), (579, 354, 3), (581, 267, 3), (583, 404, 3), (588, 317, 3), (590, 254, 3), (608, 368, 3), (610, 473, 3), (611, 283, 3), (625, 522, 3), (629, 312, 3), (645, 179, 3)]\n"
     ]
    }
   ],
   "source": [
    "print(sort_by_hight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(334, 124, 3), (362, 171, 3), (502, 174, 3), (645, 179, 3), (525, 191, 3), (481, 198, 3), (483, 208, 3), (570, 225, 3), (529, 238, 3), (502, 240, 3), (523, 245, 3), (495, 247, 3), (590, 254, 3), (572, 256, 3), (581, 267, 3), (543, 274, 3), (492, 277, 3), (611, 283, 3), (553, 304, 3), (629, 312, 3), (522, 313, 3), (588, 317, 3), (542, 319, 3), (574, 329, 3), (579, 354, 3), (519, 359, 3), (608, 368, 3), (525, 371, 3), (568, 397, 3), (583, 404, 3), (535, 419, 3), (528, 441, 3), (610, 473, 3), (578, 485, 3), (625, 522, 3)]\n"
     ]
    }
   ],
   "source": [
    "print(sort_by_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All toorh_img scaned 35 data files. Splitting dataset into 31 training files and 4 validation files\n"
     ]
    }
   ],
   "source": [
    "#split data for train and validate\n",
    "import os \n",
    "tooth_img = '/root/notebooks/0858611-2/dental/model/tooth_data'\n",
    "image_size = [256,256] #\n",
    "\n",
    "batch_size = 64 \n",
    "EPOCHS = 5\n",
    "train_data_rate = 0.9 #default=0.9 means 90 % data for training 10 % for  validation\n",
    "\n",
    "classes = ['Outside', ' middle', 'inside']\n",
    "\n",
    "file_list = []\n",
    "file_name = os.listdir(tooth_img)\n",
    "\n",
    "for file_name in os.listdir(tooth_img):\n",
    "    if file_name[-3:] == 'png':\n",
    "        path = os.path.join(tooth_img, file_name)\n",
    "        file_list.append(path)\n",
    "        \n",
    "training_num = int(len(file_list)* 0.9)\n",
    "train_data = file_list[:training_num]\n",
    "validation_data = file_list[training_num:]\n",
    "print(\"All toorh_img scaned {} data files. Splitting dataset into {} training files and {} validation files\".format(len(file_list), len(train_data), len(validation_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv to get label\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = '/root/notebooks/0858611-2/dental/model/data.csv'\n",
    "data = pd.read_csv(csv_path) \n",
    "data.head()\n",
    "train_label = data['symptom'][:training_num]\n",
    "validation_label = data['symptom'][training_num:]\n",
    "#print(train_label[:5])\n",
    "#print( data['Image Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data\n",
    "# train_label\n",
    "# validation_data\n",
    "# validation_label\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 256, 256, 3)\n",
      "(4, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "#img to array and resize \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "train_data_array = []\n",
    "for img_path in train_data:\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img,(256,256))\n",
    "    train_data_array.append(img)\n",
    "train_data_array = np.array(train_data_array)\n",
    "\n",
    "validation_data_array = []\n",
    "for img_path in validation_data:\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img,(256,256))\n",
    "    validation_data_array.append(img)\n",
    "validation_data_array = np.array(validation_data_array)\n",
    "\n",
    "train_label_array =[]\n",
    "for symptom in train_label:\n",
    "    if symptom == 'E':\n",
    "        train_label_array.append(1)\n",
    "    if symptom == 'M':\n",
    "        train_label_array.append(2)\n",
    "    if symptom == 'H':\n",
    "        train_label_array.append(1)\n",
    "        \n",
    "train_label_array = np.array(train_label_array)\n",
    "\n",
    "validation_label_array =[]\n",
    "for symptom in validation_label:\n",
    "    if symptom == 'E':\n",
    "        validation_label_array.append(1)\n",
    "    if symptom == 'M':\n",
    "        validation_label_array.append(2)\n",
    "    if symptom == 'H':\n",
    "        validation_label_array.append(1)\n",
    "        \n",
    "validation_label_array = np.array(validation_label_array)\n",
    "print(train_data_array.shape)\n",
    "print(validation_data_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#pretrained_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=[*image_size, 3])\n",
    "#pretrained_model.trainable = True\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     #pretrained_model,\n",
    "#     tf.keras.layers.Conv2D(kernel_size=3, filters=16, padding='same', activation='relu', input_shape=[*image_size, 3]),\n",
    "#     tf.keras.layers.Conv2D(kernel_size=3, filters=30, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "#     tf.keras.layers.Conv2D(kernel_size=3, filters=60, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "#     tf.keras.layers.Conv2D(kernel_size=3, filters=90, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "#     tf.keras.layers.Conv2D(kernel_size=3, filters=110, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "#     tf.keras.layers.Conv2D(kernel_size=3, filters=130, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(kernel_size=1, filters=40, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     tf.keras.layers.Dense(5, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss= 'categorical_crossentropy',\n",
    "#     metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31 samples\n",
      "Epoch 1/5\n",
      "31/31 [==============================] - 2s 70ms/sample - loss: 131.7582 - accuracy: 0.0968\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 1s 32ms/sample - loss: 15597.1768 - accuracy: 0.6774\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 1s 32ms/sample - loss: 32550.4316 - accuracy: 0.3548\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 1s 33ms/sample - loss: 5589.9756 - accuracy: 0.5484\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 1s 32ms/sample - loss: 18867.0664 - accuracy: 0.6774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5bb838b860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(256, 256,3)),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "predictions = model(train_data_array[:1]).numpy()\n",
    "tf.nn.softmax(predictions).numpy()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam',\n",
    "               loss=loss_fn,\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data_array, train_label_array, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 17178.0918 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17178.091796875, 0.5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_data_array,  validation_label_array, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
